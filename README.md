# Проект "PROSEPT"

## Задача: разработка решения, которое автоматизирует процесс сопоставления реализуемыми товарами дилеров с товаров заказчика.

**Распредение задач:**
* Денис - разработка функций для очистки текста, выведение из текста категориальных признаков, собрать уникальные слова с названий всех платформ
    
* Андрей - разработка решения для задачи сопоставления и поиска ближайших соседей, стандартизация категориальных признаков
    
* Ирина - разработка функции лемматизации текста, тестирование машинного обучения

### Используемые библиотеки

pandas, numpy, re, nltk, faiss, sklearn, spacy

### Данные


- marketing_dealer.csv - данные о дилерах
- marketing_dealerprice.csv - результат работы парсера площадок дилеров
- marketing_product.csv - список товаров, которые производит и распространяет 
заказчи
- marketing_productdealerkey.csv - таблица матчинга товаров заказчика и товаров 
дилеровк


## Проводимая работа


### Предварительный анализ данных

В marketing_dealerprice у нас данные с парсинга имеюющие ключи которые можно сопоставить с данными от производителя через marketing_productdealerkey. Таким образом получая сопоставленные данные:
- наименования товара от дилеров
- наименования товаров от производителя
- цены дилеров
- цены рекомендованные производителем
- артикула дилеров и производителей

### Предобработка данных

- За основной признак мы берем наименования товаров, которые предлагают производитель и диллеры. Из этих признаков мы извлекли полезную информацию.
Например: объем продукции, единицы измерения, а также артикулы (если они есть). Также немного преобразуем текст названий товаров (приводим к нижнему регистру, чистим от знаков)

- Также мы предположили, что название товара у производителя можно собрать из разных колонок `name_1c`, `ozon_name`, `name`, `wb_name`, чтобы извлечь как можно больше информации из товаров производителя
 Образовавшиеся пропуски заполняем пустой строкой
- Есть пропуски в столбце с рекомендованной ценой, их мало, решили заполнить медианой
- Провели лемматизацию текста для более правильной векторизации текста
- Создали две таблицы. Первая: base - данные производителя, где индексы - это id товаров. Вторая: train - соответствие запроса к парсеру и правильного ответа к продукции
- Для векторизации текста названий товаров объединим их все в один корпус
- Убрали из таблицы столбец product_id и сохранили его в другую переменную



### Поиск ближайших соседей

- Создали функцию для подсчета accuracy@15, а также создали словарь для нахождения индекса товара в базовом наборе данных

  Метрика **accuracy для ближайших 15** соседей составляет **93%**
  
- Вывели данные где для каждого запроса выдается 15 ближайших подходящих товаров производителя
- Проставили Таргеты по правильным ответам
- К этим данным добавляем ранее выведенные категориальные признаки

### Машинное обучение 

**Метрики:** Выбирали из auc_roc, precision, recall. Остановились на auc_roc

- Посмотрели балансировку ответов. У нас получился сильный дисбаланс, что в принципе нормально. Создали две функции для балансировки (upsample, downsample)
- На кросс валидации прошлись с балансировкой downsample
    * Лес - AUC ROC 96%
    * Дерево решений - AUC ROC 89%
- На кросс валидации прошлись с балансировкой upsample
    * Лес - AUC ROC 99,9%
    * Дерево решений - AUC ROC 98,9%
 
На тест взяли Лес с upsample и результат - 85,7%

## Проблемы с которыми столкнулись

- Не уверены в корректности машинного обучения (тетрадь Prosept model)?
- Как подобрать ответы после машинного обучения?
- В какой момент правильно делать разделение на выборки (train_test_split) если мы уже приходим с таблицей каждый к каждому? (для одного 15 близких)?
- Как составить корректную работоспособную mein_function?

